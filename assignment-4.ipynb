{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661b239e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24592\\268256756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Extract the data from each cell in the row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mcells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"td\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0martist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "\n",
    "ranks = []\n",
    "names = []\n",
    "artists = []\n",
    "upload_dates = []\n",
    "views = []\n",
    "\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    \n",
    "    cells = row.find_all(\"td\")\n",
    "    rank = cells[0].text.strip()\n",
    "    name = cells[1].text.strip()\n",
    "    artist = cells[2].text.strip()\n",
    "    upload_date = cells[3].text.strip()\n",
    "    view_count = cells[4].text.strip()\n",
    "    \n",
    "    \n",
    "    ranks.append(rank)\n",
    "    names.append(name)\n",
    "    artists.append(artist)\n",
    "    upload_dates.append(upload_date)\n",
    "    views.append(view_count)\n",
    "\n",
    "\n",
    "for i in range(len(ranks)):\n",
    "    print(f\"Rank: {ranks[i]}\")\n",
    "    print(f\"Name: {names[i]}\")\n",
    "    print(f\"Artist: {artists[i]}\")\n",
    "    print(f\"Upload Date: {upload_dates[i]}\")\n",
    "    print(f\"Views: {views[i]}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56746a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question --2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90cc9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Collecting chromedriver-binary\n",
      "  Downloading chromedriver-binary-114.0.5735.16.0.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Building wheels for collected packages: chromedriver-binary\n",
      "  Building wheel for chromedriver-binary (setup.py): started\n",
      "  Building wheel for chromedriver-binary (setup.py): finished with status 'done'\n",
      "  Created wheel for chromedriver-binary: filename=chromedriver_binary-114.0.5735.16.0-py3-none-any.whl size=6566158 sha256=cfaa833ebd521b7fad322efbc9a87809142f8b4edb69be43f6acfc4be079b5d8\n",
      "  Stored in directory: c:\\users\\ritvik bhardwaj\\appdata\\local\\pip\\cache\\wheels\\95\\b1\\2b\\2e38b75bdbd062ae12b80ac099cd60a9335bed62993bb4a41d\n",
      "Successfully built chromedriver-binary\n",
      "Installing collected packages: chromedriver-binary\n",
      "Successfully installed chromedriver-binary-114.0.5735.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium chromedriver-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3397c0f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".navigation__item--international\"}\n  (Session info: headless chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00E48893+48451]\n\t(No symbol) [0x00DDB8A1]\n\t(No symbol) [0x00CE5058]\n\t(No symbol) [0x00D10467]\n\t(No symbol) [0x00D1069B]\n\t(No symbol) [0x00D3DD92]\n\t(No symbol) [0x00D2A304]\n\t(No symbol) [0x00D3C482]\n\t(No symbol) [0x00D2A0B6]\n\t(No symbol) [0x00D07E08]\n\t(No symbol) [0x00D08F2D]\n\tGetHandleVerifier [0x010A8E3A+2540266]\n\tGetHandleVerifier [0x010E8959+2801161]\n\tGetHandleVerifier [0x010E295C+2776588]\n\tGetHandleVerifier [0x00ED2280+612144]\n\t(No symbol) [0x00DE4F6C]\n\t(No symbol) [0x00DE11D8]\n\t(No symbol) [0x00DE12BB]\n\t(No symbol) [0x00DD4857]\n\tBaseThreadInitThunk [0x75877D59+25]\n\tRtlInitializeExceptionChain [0x7756B74B+107]\n\tRtlClearBits [0x7756B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24592\\433084658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmenu_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"navigation__item--international\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mmenu_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    829\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".navigation__item--international\"}\n  (Session info: headless chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00E48893+48451]\n\t(No symbol) [0x00DDB8A1]\n\t(No symbol) [0x00CE5058]\n\t(No symbol) [0x00D10467]\n\t(No symbol) [0x00D1069B]\n\t(No symbol) [0x00D3DD92]\n\t(No symbol) [0x00D2A304]\n\t(No symbol) [0x00D3C482]\n\t(No symbol) [0x00D2A0B6]\n\t(No symbol) [0x00D07E08]\n\t(No symbol) [0x00D08F2D]\n\tGetHandleVerifier [0x010A8E3A+2540266]\n\tGetHandleVerifier [0x010E8959+2801161]\n\tGetHandleVerifier [0x010E295C+2776588]\n\tGetHandleVerifier [0x00ED2280+612144]\n\t(No symbol) [0x00DE4F6C]\n\t(No symbol) [0x00DE11D8]\n\t(No symbol) [0x00DE12BB]\n\t(No symbol) [0x00DD4857]\n\tBaseThreadInitThunk [0x75877D59+25]\n\tRtlInitializeExceptionChain [0x7756B74B+107]\n\tRtlClearBits [0x7756B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "\n",
    "webdriver_service = Service('path_to_chromedriver_executable')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=webdriver_service, options=chrome_options)\n",
    "\n",
    "\n",
    "url = \"https://www.bcci.tv/\"\n",
    "\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "menu_item = driver.find_element(By.CLASS_NAME, \"navigation__item--international\")\n",
    "menu_item.click()\n",
    "\n",
    "\n",
    "fixtures_link = driver.find_element(By.LINK_TEXT, \"Fixtures\")\n",
    "fixtures_link.click()\n",
    "\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "\n",
    "fixtures_container = driver.find_element(By.CLASS_NAME, \"js-list\")\n",
    "\n",
    "\n",
    "fixture_items = fixtures_container.find_elements(By.CLASS_NAME, \"fixture-list__item\")\n",
    "\n",
    "\n",
    "match_titles = []\n",
    "series_names = []\n",
    "places = []\n",
    "dates = []\n",
    "times = []\n",
    "\n",
    "\n",
    "for item in fixture_items:\n",
    "    \n",
    "    match_title = item.find_element(By.CLASS_NAME, \"fixture-date\").text.strip()\n",
    "    series_name = item.find_element(By.CLASS_NAME, \"u-unskewed-text\").text.strip()\n",
    "    place = item.find_element(By.CLASS_NAME, \"fixture-stadium\").text.strip()\n",
    "    date = item.find_element(By.CLASS_NAME, \"fixture-date__day\").text.strip()\n",
    "    time = item.find_element(By.CLASS_NAME, \"fixture-time\").text.strip()\n",
    "    \n",
    "    \n",
    "    match_titles.append(match_title)\n",
    "    series_names.append(series_name)\n",
    "    places.append(place)\n",
    "    dates.append(date)\n",
    "    times.append(time)\n",
    "\n",
    "\n",
    "for i in range(len(match_titles)):\n",
    "    print(f\"Match Title: {match_titles[i]}\")\n",
    "    print(f\"Series: {series_names[i]}\")\n",
    "    print(f\"Place: {places[i]}\")\n",
    "    print(f\"Date: {dates[i]}\")\n",
    "    print(f\"Time: {times[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question--3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "economy_link = driver.find_element_by_xpath(\"//a[contains(text(), 'Economy')]\")\n",
    "economy_link.click()\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "economy_page_html = driver.page_source\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(economy_page_html, \"html.parser\")\n",
    "table = soup.find(\"table\", class_=\"display compact\")\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# Extract the details of State-wise GDP\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all(\"td\")\n",
    "    rank = cells[0].text.strip()\n",
    "    state = cells[1].text.strip()\n",
    "    gdp_18_19 = cells[2].text.strip()\n",
    "    gdp_19_20 = cells[3].text.strip()\n",
    "    share_18_19 = cells[4].text.strip()\n",
    "    gdp_billion = cells[5].text.strip()\n",
    "    \n",
    "    print(\"Rank:\", rank)\n",
    "    print(\"State:\", state)\n",
    "    print(\"GSDP(18-19) - at current prices:\", gdp_18_19)\n",
    "    print(\"GSDP(19-20) - at current prices:\", gdp_19_20)\n",
    "    print(\"Share(18-19):\", share_18_19)\n",
    "    print(\"GDP($ billion):\", gdp_billion)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "explore_menu = driver.find_element_by_xpath(\"//summary[contains(text(), 'Explore')]\")\n",
    "explore_menu.click()\n",
    "\n",
    "\n",
    "trending_option = driver.find_element_by_xpath(\"//a[contains(text(), 'Trending')]\")\n",
    "trending_option.click()\n",
    "\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "\n",
    "trending_page_html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(trending_page_html, \"html.parser\")\n",
    "repositories = soup.find_all(\"article\")\n",
    "\n",
    "for repository in repositories:\n",
    "    title = repository.find(\"h1\").text.strip()\n",
    "    description = repository.find(\"p\").text.strip()\n",
    "    contributors_count = repository.find(\"a\", class_=\"muted-link\").text.strip().split()[0]\n",
    "    language = repository.find(\"span\", itemprop=\"programmingLanguage\").text.strip()\n",
    "    \n",
    "    print(\"Repository Title:\", title)\n",
    "    print(\"Repository Description:\", description)\n",
    "    print(\"Contributors Count:\", contributors_count)\n",
    "    print(\"Language Used:\", language)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95793624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32fc1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://www.billboard.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    charts_option = driver.find_element(By.LINK_TEXT, \"Charts\")\n",
    "    charts_option.click()\n",
    "\n",
    "    \n",
    "    hot_100_link = driver.find_element(By.LINK_TEXT, \"Hot 100\")\n",
    "    hot_100_link.click()\n",
    "\n",
    "    \n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    \n",
    "    hot_100_page_html = driver.page_source\n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(hot_100_page_html, \"html.parser\")\n",
    "    songs = soup.find_all(\"li\", class_=\"chart-list__element\")\n",
    "\n",
    "    \n",
    "    for song in songs:\n",
    "        try:\n",
    "            song_name = song.find(\"span\", class_=\"chart-element__information__song\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            song_name = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            artist_name = song.find(\"span\", class_=\"chart-element__information__artist\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            artist_name = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            last_week_rank = song.find(\"span\", class_=\"chart-element__meta text--last\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            last_week_rank = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            peak_rank = song.find(\"span\", class_=\"chart-element__meta text--peak\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            peak_rank = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            weeks_on_board = song.find(\"span\", class_=\"chart-element__meta text--week\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            weeks_on_board = \"N/A\"\n",
    "        \n",
    "        print(\"Song Name:\", song_name)\n",
    "        print(\"Artist Name:\", artist_name)\n",
    "        print(\"Last Week Rank:\", last_week_rank)\n",
    "        print(\"Peak Rank:\", peak_rank)\n",
    "        print(\"Weeks on Board:\", weeks_on_board)\n",
    "        print(\"------------------------------------\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Load the website\n",
    "    url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"in-article sortable\")\n",
    "\n",
    "    \n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows[1:]:\n",
    "        try:\n",
    "            cells = row.find_all(\"td\")\n",
    "            book_name = cells[1].text.strip()\n",
    "            author_name = cells[2].text.strip()\n",
    "            volumes_sold = cells[3].text.strip()\n",
    "            publisher = cells[4].text.strip()\n",
    "            genre = cells[5].text.strip()\n",
    "\n",
    "            print(\"Book Name:\", book_name)\n",
    "            print(\"Author Name:\", author_name)\n",
    "            print(\"Volumes Sold:\", volumes_sold)\n",
    "            print(\"Publisher:\", publisher)\n",
    "            print(\"Genre:\", genre)\n",
    "            print(\"------------------------------------\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Error occurred while scraping row:\", row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "finally:\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40108f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    series_list = soup.find(\"div\", class_=\"lister-list\")\n",
    "\n",
    "    \n",
    "    series_items = series_list.find_all(\"div\", class_=\"lister-item-content\")\n",
    "    for series_item in series_items:\n",
    "        try:\n",
    "            name = series_item.find(\"a\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            name = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            year_span = series_item.find(\"span\", class_=\"lister-item-year\").text.strip(\"()\").strip()\n",
    "        except NoSuchElementException:\n",
    "            year_span = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            genre = series_item.find(\"span\", class_=\"genre\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            genre = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            run_time = series_item.find(\"span\", class_=\"runtime\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            run_time = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            ratings = series_item.find(\"strong\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            ratings = \"N/A\"\n",
    "        \n",
    "        try:\n",
    "            votes = series_item.find(\"span\", attrs={\"name\": \"nv\"}).text.strip()\n",
    "        except NoSuchElementException:\n",
    "            votes = \"N/A\"\n",
    "        \n",
    "        print(\"Name:\", name)\n",
    "        print(\"Year Span:\", year_span)\n",
    "        print(\"Genre:\", genre)\n",
    "        print(\"Run Time:\", run_time)\n",
    "        print(\"Ratings:\", ratings)\n",
    "        print(\"Votes:\", votes)\n",
    "        print(\"------------------------------------\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "finally:\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://archive.ics.uci.edu/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    view_all_datasets_link = driver.find_element(By.LINK_TEXT, \"View All Data Sets\")\n",
    "    view_all_datasets_link.click()\n",
    "\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    dataset_table = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "    \n",
    "    dataset_rows = dataset_table.find_all(\"tr\")\n",
    "    for row in dataset_rows[1:]:\n",
    "        try:\n",
    "            cells = row.find_all(\"td\")\n",
    "            dataset_name = cells[0].text.strip()\n",
    "            data_type = cells[1].text.strip()\n",
    "            task = cells[2].text.strip()\n",
    "            attribute_type = cells[3].text.strip()\n",
    "            num_instances = cells[4].text.strip()\n",
    "            num_attributes = cells[5].text.strip()\n",
    "            year = cells[6].text.strip()\n",
    "\n",
    "            print(\"Dataset Name:\", dataset_name)\n",
    "            print(\"Data Type:\", data_type)\n",
    "            print(\"Task:\", task)\n",
    "            print(\"Attribute Type:\", attribute_type)\n",
    "            print(\"Number of Instances:\", num_instances)\n",
    "            print(\"Number of Attributes:\", num_attributes)\n",
    "            print(\"Year:\", year)\n",
    "            print(\"------------------------------------\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Error occurred while scraping row:\", row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "finally:\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    recruiters_option = driver.find_element(By.LINK_TEXT, \"Recruiters\")\n",
    "    recruiters_option.click()\n",
    "\n",
    "    \n",
    "    driver.switch_to.window(driver.window_handles[-1]\n",
    "                            \n",
    "                                                        \n",
    "    search_pane = driver.find_element(By.ID, \"root-autocomplete\")\n",
    "    search_pane.send_keys(\"Data Science\")\n",
    "\n",
    "    search_button = driver.find_element(By.ID, \"root-keywords\")\n",
    "    search_button.click()\n",
    "\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    \n",
    "    recruiter_list = driver.find_element(By.CSS_SELECTOR, \"div.row\")\n",
    "    recruiters = recruiter_list.find_elements(By.CSS_SELECTOR, \"article\")\n",
    "\n",
    "    \n",
    "    for recruiter in recruiters:\n",
    "        try:\n",
    "            name = recruiter.find_element(By.CSS_SELECTOR, \"a.name\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            name = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            designation = recruiter.find_element(By.CSS_SELECTOR, \"span.designation\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            designation = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            company = recruiter.find_element(By.CSS_SELECTOR, \"a.company\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            company = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            skills = recruiter.find_element(By.CSS_SELECTOR, \"div.skills\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            skills = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            location = recruiter.find_element(By.CSS_SELECTOR, \"div.location\").text.strip()\n",
    "        except NoSuchElementException:\n",
    "            location = \"N/A\"\n",
    "\n",
    "        print(\"Name:\", name)\n",
    "        print(\"Designation:\", designation)\n",
    "        print(\"Company:\", company)\n",
    "        print(\"Skills They Hire For:\", skills)\n",
    "        print(\"Location:\", location)\n",
    "        print(\"------------------------------------\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n",
    "\n",
    "finally:\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
